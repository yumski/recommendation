---
title: "Movie Recommendation"
author: "Cong Feng"
date: "11/18/2020"
output: 
  pdf_document:
    df_print: kable
    number_sections: yes
highlight-style: tango
mainfront: Calibri-light
fontsize: 10pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=4, fig.height=3)

library(ggthemes)
library(recosystem)
```

# Introduction

Recommendation systems are an integral part of the modern business. Companies across the world utilize these type of systems to recommend products, movies or even social groups to enhance their user's experience. In this project, we are working a data set of ~10 million observation to build a recommendation system for movies. 

The goal of the project is the minimize the RMSE (root mean square error). It is the formula to determine the effectiveness of the prediction compared to the test data.

The formula is defined:
$$RMSE =\sqrt{\frac{1}{N}\sum_{u,i}(\hat{y}_{u,i}-y_{u,i})^2}$$
it takes the square root of the average of the  square of the residual $$(\hat{y}_{u,i}-y_{u,i})$$ for user $u$ and movie $i$. This allow us to calculate how close our prediction was to the actual user rating on the validation set.

```{r}
RMSE <- function(predicted_rating, actual_rating){
  sqrt(mean((predicted_rating - actual_rating)^2))
}
```

Will be our RMSE function for final testing.

# Exploratory Data Analysis

## Examining the data set

```{r Loading Data, warning=FALSE, include=FALSE}

library(tidyverse)
library(caret)
library(knitr)
library(ggplot2)
library(data.table)

##########################################################
# Create edx set, validation set (final hold-out test set)
##########################################################

# Note: this process could take a couple of minutes

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")

# if using R 4.0 or later:
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(movieId),
                                           title = as.character(title),
                                           genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding") # if using R 3.5 or earlier, use `set.seed(1)`
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)


```

We begin by downloading and splitting the data into 2 sets "edx" and "validation" set. The edx set will be our training set and validation set is our test set. The total observations is about ~10 million and it is split 90% for training and 10% for testing.

A quick look into the $edx$ data structure shows:
```{r message=FALSE, warning=FALSE}
dim(edx)
```


```{r Examining Data, echo=FALSE}
head(edx)
```

The data is split into 6 columns consist of userId, movieId, date, rating, title and genre.

```{r unique user and movie}
c(unique_users = length(unique(edx$userId)), unique_movies = length(unique(edx$movieId)))
```

We see the number for the unique number of users and movies above. Right away we see from the dimensions not every user rates every movie, this makes sense as not every user will rate every movie they watch.

## Distribution of Numbers of Rating

Let's take a look at the breakdown of the distribution of rating


```{r echo=FALSE, message=FALSE, warning=FALSE, fig.align = "center"}
user_avg_n <- edx %>%
  group_by(userId) %>%
  summarize(n = n()) %>%
  summarize(avg = mean(n)) %>%
  pull(avg)

edx %>%
  group_by(userId) %>%
  summarize(n = n()) %>%
  ggplot(aes(n)) +
  geom_histogram(color = "white", fill = "blue") +
  scale_x_log10() +
  geom_vline(xintercept = user_avg_n, color = "red") +
  annotate("text", x = 500, y = 5500, label = "Average number of ratings", color = "Red") +
  xlab("Number of ratings (log 10 scale)") +
  ylab("Number of users") +
  ggtitle("User - Number of Ratings Distribution") +
  theme_clean()

```


```{r, echo = FALSE, message=FALSE, warning=FALSE, fig.align = "center"}
movie_avg_rating <- edx %>%
  group_by(movieId) %>%
  summarize(n = n()) %>%
  summarize(avg = mean(n)) %>%
  pull(avg)

edx %>%
  group_by(movieId) %>%
  summarize(n = n()) %>%
  ggplot(aes(n)) +
  geom_histogram(bins = 15, color = "white", fill = "blue") +
  geom_vline(xintercept = movie_avg_rating, color = "red") +
  annotate("text", x = 5000, y = 1250, label = "Average number of ratings", color = "red") +
  scale_x_log10() +
  xlab("Number of Ratings (log 10 scale)") +
  ylab("Number of Movies") +
  ggtitle("Movies - Number of Ratings Distribution") +
  theme_clean()
```

There is a big difference between the distribution of numbers for the user set and the movie set. In the user set we see a large number of ratings is done by a small percentage of the users. The movie distribution however follows a more symmetrical distribution.

## Distribution of Ratings

Here is how the actual rating is distributed.

```{r, echo = FALSE, message=FALSE, warning=FALSE, fig.align = "center"}
edx %>%
  group_by(rating) %>%
  summarize(n = n()) %>%
  ggplot(aes(rating, n)) +
  geom_line() +
  geom_vline(xintercept = 3.512465, color = "red") +
  annotate("text", x = 4.25, y = 100, label = "Average Rating", color = "Red") +
  xlab("Ratings") +
  ylab("Number of ratings") +
  theme_clean() +
  ggtitle("Rating Distribution")
```

It is a lot more likely for users to pick a whole number compared to half ratings and majority of the users gave movies either a 3 or 4. It is also very unlikely for a movie to receive a bad rating compared to an average to great rating.

```{r, echo = FALSE, message=FALSE, warning=FALSE, fig.align = "center"}
edx %>%
  group_by(movieId) %>%
  summarize(rating = mean(rating), n = n(), movieId = first(movieId)) %>%
  ggplot(aes(n, rating)) +
  scale_x_sqrt() +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "loess") +
  xlab("Number of Ratings (square root scale)") +
  ylab("Ratings") +
  theme_clean()  +
  ggtitle("Rating Distribution for Individual Movies")

```
```{r, echo = FALSE, message=FALSE, warning=FALSE}
edx %>%
  group_by(userId) %>%
  summarize(rating = mean(rating), n = n(), userId = first(userId)) %>%
  ggplot(aes(n, rating)) +
  scale_x_sqrt() +
  geom_point(alpha = 0.3) +
  xlab("Number of Ratings (square root scale)") +
  ylab("Ratings") +
  theme_clean() +
  ggtitle("Rating Distribution for Individual Users")
```
Examining the rating distribution between movies and users, we notice some similarities. At low number of ratings; the rating are more varied. However they both normalized towards the mean as the number of ratings increase.

*Did not utilize the smoothing function for the Rating Distribution for Individual Users due to hardware limitations*

```{r echo= FALSE, message=FALSE, warning=FALSE}
edx %>%
  group_by(movieId) %>%
  summarize(movieId = first(movieId), n = n(), stan_dev = sd(rating)) %>%
  mutate(group = cut(n,
                     breaks = c(0, mean(n), Inf),
                     labels = c("< than 843", "> than 843"))) %>%
  ggplot(aes(stan_dev, fill = group)) +
  geom_density(alpha = 0.5) +
  xlab("Standard Deviation") +
  ylab("Count") +
  theme_clean() +
  ggtitle("Standard Deviation of Rating in Movies",
          subtitle = "Average number of ratings = 843")
  
```

```{r, echo = FALSE, message = FALSE, warning = FALSE, fig.align = "center"}
edx %>%
  group_by(userId) %>%
  summarize(userId = first(userId), n = n(), stan_dev = sd(rating)) %>%
  mutate(group = cut(n,
                     breaks = c(0, mean(n), Inf),
                     labels = c("< 129", "> 129"))) %>%
  ggplot(aes(stan_dev, fill = group)) +
  geom_density(alpha = 0.5) +
  xlab("Standard Deviation") +
  ylab("Density") +
  theme_clean() +
  ggtitle("Standard Deviation of Ratings for Users",
          subtitle = "Average number of ratings = 129")
```

When we take a look at the standard deviation of the user and movie data set, we can see a big difference. For the rating of movies, as the movie get rated more the variance of the rating is lower. However when we look at the user's rating distribution, it's relatively similar variance between someone who rates many movies and someone who does not.

## Matrix Factorization

Another powerful tool in machine learning is matrix factorization. The data is converted to a matrix where each row is an individual user and each column is an individual movie and their respective ratings will be populated. 

```{r message=FALSE, warning=FALSE}
top_m <- edx %>%
  group_by(movieId) %>%
  summarize(n = n()) %>%
  arrange(desc(n)) %>%
  slice(1:20)

top_u <- edx %>%
  group_by(userId) %>%
  summarize(n = n()) %>%
  arrange(desc(n)) %>%
  slice(1:20)

top_um <- edx %>%
  right_join(top_m, by = "movieId") %>%
  right_join(top_u, by = "userId") %>%
  select(title, userId, rating) %>%
  spread(title, rating) %>%
  as.matrix()

```
To make a manageable matrix, I took the top 20 most rated movies and users as a sample.

```{r message=FALSE, warning=FALSE}
d <- dist(top_um)

h <- hclust(d)
plot(h, cex = 0.65, main = "User Clusters", xlab = "")

```
One of the important methods of calculating similarity is by calculating the distance between objects. With this small sample size we can already start observing clusters of users. This shows that some users like similar taste in movies while very different from others. This is also consistent with common intuition.
```{r message=FALSE, warning=FALSE}
heatmap(as.matrix(d), col = RColorBrewer::brewer.pal(11, "Spectral"))
```
We can also visualize this better with a heatmap. The color range from dark red to purple, dark red meaning they're very similar to purple meaning the opposite.

# Modeling

Our goal for this project is to have an RMSE of < 0.86490.
```{r Build train and test set, message=FALSE, warning=FALSE}
set.seed(5, sample.kind = "Rounding")

#Create 10% of data partition for testing
ind <- createDataPartition(edx$rating, times = 1, p = 0.2, list = FALSE)

train_set <- edx[-ind,]
temp_test <- edx[ind,]

#Validate to make sure entries in test set are also in train set.

test_set <- temp_test %>%
  semi_join(train_set, by = "movieId") %>%
  semi_join(train_set, by = "userId")

#Add the removed rows back into the training set
removed <- anti_join(temp_test, test_set)
train_set <- rbind(train_set, removed)

rm(temp_test)
```
First we will split the original edx dataset into a training and test set. We do not want to over-train or over-smooth our model by training it with the validation set at all. The ratio for this partition is 90/10, we will train and test on this set before computing the final RMSE on the validation set.

## Linear Regression

### Baseline

To establish a baseline, we are going to predict the average rating for every movie and user.

$$\hat{y}_{u,i}=\mu$$
$$\hat{y}_{u,i}$$ is the prediction for movie i by user u.
$$\mu$$ is the average rating across all movies and users.

```{r message=FALSE, warning=FALSE}
mu <- mean(train_set$rating)
goal <- 0.8649000

result <- data.frame(Method = "Project Goal", 
                 RMSE = goal)
result <- bind_rows(result,
                    data.frame(Method = "Baseline",
                           RMSE = RMSE(mu, test_set$rating)))
result

```
It's not an accurate prediction the RMSE is over 1, however it does provide a good baseline for us to build on.

### User and Movie Bias

Our data analysis showed that each movie and user have different bias, we can account for those with the formula below.

$$\hat{y}_{u,i}=\mu+b_i+b_u+\epsilon_{u,i}$$
In this formula we added bi bias for movie i and bu bias for user u, we also included the standard error of these ratings $$\epsilon_{u,i}$$.

```{r Movie Bias, message=FALSE, warning=FALSE}
b_i <- train_set %>%
  group_by(movieId) %>%
  summarize(b_i = mean(rating - mu))

b_i %>%
  ggplot(aes(b_i)) +
  geom_histogram(color = "white", fill = "blue") +
  ggtitle("Movie Bias") +
  theme_clean()

```

The graph for movie bias is consistent with our findings in the movie distribution graph. Majority of the movies are rated very close to the average, which some exceptional movies receiving a high rating. The movie bias is skewed towards negative, meaning majority of the movies are rated below the average.

```{r message=FALSE, warning=FALSE}
pred_b_i <- mu + test_set %>%
  left_join(b_i, by = "movieId") %>%
  .$b_i

result <- bind_rows(result,
                    data.frame(Method = "With Movie Bias",
                           RMSE = RMSE(pred_b_i, test_set$rating)))
result
                    
```

There was a significant decrease in RMSE with the movie bias accounted for. We will do the same with the user bias.


```{r message=FALSE, warning=FALSE}
b_u <- train_set %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating - mu))

b_u %>%
  ggplot(aes(b_u)) +
  geom_histogram(color = "white", fill = "blue") +
  theme_clean() +
  ggtitle("User Bias")
```

The distribution of the user bias is similar to the one for the movies. However, unlike the the movie bias, the user bias is a balanced distribution. The majority of the users rate very close to the average.
```{r message=FALSE, warning=FALSE}

pred_bui <- test_set %>%
  left_join(b_u, by = "userId") %>%
  left_join(b_i, by = "movieId") %>%
  mutate(pred = mu + b_i + b_u) %>%
  .$pred

result <- bind_rows(result,
                    data.frame(Method = "With Movie and User bias",
                               RMSE = RMSE(pred_bui, test_set$rating)))
result
```

### Regularization

With the user and movie bias, there is a significant decrease in RMSE compared to the baseline. However, we are still not at our RMSE target. 
```{r message=FALSE, warning=FALSE}
titles <- train_set %>%
  select(movieId, title) %>%
  distinct()

b_i %>%
  left_join(titles, by = "movieId") %>%
  arrange(desc(b_i)) %>%
  group_by(title) %>%
  summarize(count = n()) %>%
  slice(1:10)
```
Here is the top 10 movies according to our adjusted movie bias rating. It's all movies that have 1 rating and are obscure. This finding is consistent with the movie rating distribution plot. The movies with a few ratings was very varied compared to the movies with a lot of ratings and may not reflect the rating of a lot of users. To account for this we need to add the least square method to our model.

$$\sum_{u,i}(y_{u,i}-\mu-b_i)^2+\lambda\sum_ib^2_i$$
To account for the low number of rating, we introduce a variable to penalize the regression to control the variability. This method will shrink the bias towards 0 when the number of rating is low, but will be effectively ignored when it has a lot of rating.

We will run a range of penalty from 0 to 10 to determine the optimal penalty.
```{r message=FALSE, warning=FALSE}
#define lambda range
lambdas <- seq(0,10,0.25)


regularization_rmse <- sapply(lambdas, function(l){
  
  #movie bias regularized
  b_i_r <- train_set %>%
    group_by(movieId) %>%
    summarize(b_i_r = sum(rating - mu)/(n()+l))
  
  #movie + user bias regularized
  b_u_r <- train_set %>%
    left_join(b_i_r, by="movieId") %>%
    group_by(userId) %>%
    summarize(b_u_r = sum(rating - b_i_r - mu)/(n()+l))
  
  predicted_ratings <- test_set %>%
    left_join(b_i_r, by = "movieId") %>%
    left_join(b_u_r, by = "userId") %>%
    mutate(pred = mu + b_i_r + b_u_r) %>%
    .$pred
  return(RMSE(predicted_ratings, test_set$rating))
})

data.frame(Lambda = lambdas, RMSE = regularization_rmse) %>%
  ggplot(aes(x = Lambda, y = RMSE)) +
  geom_point() +
  theme_clean() +
 ggtitle("Lambda vs RMSE")

lambda <- lambdas[which.min(regularization_rmse)]
lambda
```

We see that 5.0 provides the lowest RMSE.

```{r message=FALSE, warning=FALSE}
b_i_reg <- train_set %>%
  group_by(movieId) %>%
  summarize(b_i_reg = sum(rating - mu)/(n()+lambda))

b_i_reg  %>%
  left_join(titles, by = "movieId") %>%
  arrange(desc(b_i_reg)) %>%
  slice(1:10)

```
Here is the top 10 movies after applying regularization to the model. This is more accurate as these are all well known blockbuster movies, the resulting RMSE is very close to target.

```{r message=FALSE, warning=FALSE}
result <- bind_rows(result,
                   data.frame(Method = "Regularization + Movie + User bias",
                   RMSE = min(regularization_rmse)))
result
```

## Matrix Factorization

Another popular method of machine learning method is matrix factorization. From the heatmap and dendrogram from our data analysis we saw clusters of users and movies. We can use this data to calculate how likely user u is to rate movie i based on other users of similar rating habit as them. To optimize the process, we will use the r package recosystem.

A guide to this can be found at: https://cran.r-project.org/web/packages/recosystem/vignettes/introduction.html 


```{r message=FALSE, warning=FALSE}
set.seed(1987, sample.kind = "Rounding")

# Convert train and test set to recosystem data
train_dat <- with(train_set, data_memory(user_index = userId,
                                         item_index = movieId,
                                         rating = rating))
test_dat <- with(test_set, data_memory(user_index = userId,
                                       item_index = movieId,
                                       rating = rating))

r = Reco()

# Tuning the model
opts_tune <- r$tune(train_dat, opts = list(dim = 10,
                                           niter = 10))

# Training the model with best tuning parameters
r$train(train_dat, opts = c(opts_tune$min))

```
To train the model, we applied the optimal tuning parameter through 20 iterations for the lowest RMSE.
```{r message=FALSE, warning=FALSE}
# Predict the rating
pred_reco <- r$predict(test_dat, out_memory())

result <- bind_rows(result, data.frame(Method = "Matrix Factorization",
                                       RMSE = RMSE(pred_reco, test_set$rating)))
result
```

# Validation

We have achieved the targetted RMSE through the training set. Now it's time to apply the model to the final validation set.

## Linear Model
```{r message=FALSE, warning=FALSE}
edx_mu <- mean(edx$rating)

edx_bi <- edx %>%
  group_by(movieId) %>%
  summarize(edx_bi = sum(rating - edx_mu)/(n() + lambda))

edx_bu <- edx %>%
  left_join(edx_bi, by = "movieId") %>%
  group_by(userId) %>%
  summarize(edx_bu = sum(rating - edx_bi - edx_mu)/(n() + lambda))

pred_edx_lm <- validation %>%
  left_join(edx_bi, by = "movieId") %>%
  left_join(edx_bu, by = "userId") %>%
  summarize(pred = edx_mu + edx_bi + edx_bu) %>%
  .$pred

final_results <- data.frame(Method = "Regularized bias",
                        RMSE = RMSE(pred_edx_lm, validation$rating),
                        Goal = goal)
final_results
```

## Matrix Factorization
```{r message=FALSE, warning=FALSE}
edx_dat <- with(edx, data_memory(user_index = userId,
                                 item_index = movieId,
                                 rating = rating))
v_dat <- with(validation, data_memory(user_index = userId,
                                      item_index = movieId,
                                      rating = rating))

r$train(edx_dat, opts = opts_tune$min)

v_pred_mf <- r$predict(v_dat, out_memory())


final_results <- bind_rows(final_results, data.frame(Method = "Matrix Factorization",
                                                    RMSE = RMSE(v_pred_mf, validation$rating),
                                                    Goal = goal))
final_results
```

# Conclusion

In this data science project I utilized the skills I learned in this course to build a movie recommendation algorithm. 

- Used the data analysis and visualization techniques to first observe the data to look for patterns. 

- Built two different machine learning models based on different approach. The Linear Regression model achieved RMSE of 0.8468177 and the Matrix Factorization Model achived RMSE of 0.8069243; both below the goal of 0.8469.

Overall this project was challenging and fun to work on. I got to apply the knowledge I learned from the course and built upon the examples from Professor Irizarry. Working with such a large data set did come with some challenges and limitations. I was not able to run some models due to hardware limitation. I am excited to experiment on another data set for other class project.
